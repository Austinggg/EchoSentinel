import json
from pathlib import Path
import re
import time
import requests
from openai import OpenAI
import logging


class SummaryGenerator:
    def __init__(self, config=None):
        """åˆå§‹åŒ–æ‘˜è¦ç”Ÿæˆå™¨

        Args:
            config: å¯é€‰çš„é…ç½®å‚æ•°ï¼Œå¦‚æžœä¸æä¾›åˆ™ä»Žé»˜è®¤ä½ç½®åŠ è½½
        """
        # å¦‚æžœæ²¡æœ‰æä¾›é…ç½®ï¼Œåˆ™ä»Žé»˜è®¤ä½ç½®åŠ è½½
        if config is None:
            self.config = self._load_config()
        else:
            self.config = config

        self.use_local = self.config["local_report"]

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if not self.use_local:
            self.client = OpenAI(
                api_key=self.config["report_model"]["remote_openai"]["api_key"],
                base_url=self.config["report_model"]["remote_openai"]["base_url"],
            )

        # å…¬å…±å‚æ•°
        self.max_retries = self.config["retry"]["max_retries"]
        self.retry_delay = self.config["retry"]["retry_delay"]
        self.system_prompt = self._build_system_prompt()

    def _load_config(self):
        config_path = Path(__file__).parent / "config" / "config.json"

        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨äºŽï¼š{config_path}")

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                raw_content = f.read()
                # å¤„ç†BOMå¤´
                if raw_content.startswith("\ufeff"):
                    raw_content = raw_content[1:]
                return json.loads(raw_content)
        except json.JSONDecodeError as e:
            raise ValueError(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼š{e.doc}")
        except Exception as e:
            raise RuntimeError(f"é…ç½®åŠ è½½å¤±è´¥ï¼š{str(e)}")

    def _build_system_prompt(self):
        return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ‘˜è¦ç”Ÿæˆå™¨ã€‚è¯·æ ¹æ®æä¾›çš„æ–‡æœ¬å†…å®¹å’Œå·²æå–çš„ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´ã€å…¨é¢çš„å†…å®¹æ‘˜è¦ã€‚

æ‘˜è¦è¦æ±‚ï¼š
1. æ‘˜è¦ä¸­å¿…é¡»æ˜Žç¡®åŒ…å«å·²æå–çš„æ„å›¾å’Œå…³é”®é™ˆè¿°
2. æ€»ç»“å†…å®¹çš„ä¸»é¢˜å’Œæ ¸å¿ƒè§‚ç‚¹
3. ä¿æŒå®¢è§‚ã€å‡†ç¡®çš„è¡¨è¾¾
4. æ‘˜è¦é•¿åº¦æŽ§åˆ¶åœ¨500å­—ä»¥å†…
5. æ¸…æ™°çš„æ ¼å¼è¿›è¡ŒæŽ’ç‰ˆ
6. ä½¿ç”¨ä»¥ä¸‹emojiå›¾æ ‡æˆ–æ–‡å­—æ ‡ç­¾æ¥è¡¨ç¤ºä¸åŒçš„å†…å®¹ç±»åž‹ï¼š
æ­£ç¡®ã€å¼ºè°ƒ
	
âœ…ã€ðŸŒŸã€ðŸ“Œ
è­¦å‘Šã€æ³¨æ„
	
âš ï¸ã€â—
é”™è¯¯ã€ç¼ºç‚¹
	
âŒã€ðŸ’¢
æ€»ç»“ã€ç»“è®º
	
ðŸ“ã€ðŸ”šã€ðŸ
ç›®æ ‡ã€ç”¨é€”
	
ðŸŽ¯
æç¤ºã€æŠ€å·§
	
ã€ðŸ”
é¡¹ç›®åˆ†ç±»
	
ðŸ§©ã€ðŸ“ã€ðŸ“¦


å†…å®¹ç»“æž„åº”åŒ…å«ï¼š
1. ä¸»é¢˜è¯´æ˜Žï¼šç®€è¿°å†…å®¹çš„ä¸»è¦è¯é¢˜å’Œç›®çš„
2. æ„å›¾åˆ†æžï¼šåŸºäºŽå·²æå–çš„æ„å›¾è¿›è¡Œè¡¨è¿°
3. æ ¸å¿ƒé™ˆè¿°ï¼šåŸºäºŽå·²æå–çš„å…³é”®é™ˆè¿°è¿›è¡Œæ¦‚æ‹¬
4. æ•´ä½“è¯„ä»·ï¼šå¯¹å†…å®¹è¿›è¡Œæ€»ä½“æ€§æè¿°

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
## ðŸ“å†…å®¹æ‘˜è¦

### ä¸»é¢˜
[ç®€è¦æè¿°å†…å®¹çš„ä¸»é¢˜]

### æ„å›¾
[åˆ—å‡ºå†…å®¹çš„ä¸»è¦æ„å›¾]

### ðŸ’¡æ ¸å¿ƒå†…å®¹
- [å…³é”®é™ˆè¿°1]
- [å…³é”®é™ˆè¿°2]
- [å…³é”®é™ˆè¿°3]

### ðŸ”šæ€»ç»“
[å¯¹å†…å®¹çš„æ•´ä½“è¯„ä»·å’Œæ€»ç»“]
è¯·ç¡®ä¿æ‘˜è¦å†…å®¹å®Œæ•´ã€å‡†ç¡®ï¼Œå¹¶ä¿æŒä¸ŽåŽŸæ–‡çš„ä¸€è‡´æ€§ã€‚ """

    def generate_summary(self, transcript_text, extracted_info, max_length=None):
        """
        ç”Ÿæˆå†…å®¹æ‘˜è¦

        Args:
            transcript_text: åŽŸå§‹æ–‡æœ¬å†…å®¹
            extracted_info: å·²æå–çš„ä¿¡æ¯ï¼ˆåŒ…å«intentå’Œstatementsï¼‰
            max_length: å¯é€‰çš„æœ€å¤§é•¿åº¦é™åˆ¶

        Returns:
            str: Markdownæ ¼å¼çš„æ‘˜è¦å†…å®¹
        """
        # ç»„åˆç”¨æˆ·è¾“å…¥ï¼ŒåŒ…å«åŽŸå§‹æ–‡æœ¬å’Œå·²æå–çš„ä¿¡æ¯
        user_input = self._build_user_input(transcript_text, extracted_info)

        for attempt in range(self.max_retries):
            try:
                if self.use_local:
                    summary = self._call_ollama_api(user_input)
                else:
                    summary = self._call_openai_api(user_input)

                # åº”ç”¨é•¿åº¦é™åˆ¶ï¼ˆå¦‚æžœæœ‰ï¼‰
                if max_length and len(summary) > max_length:
                    summary = summary[: max_length - 3] + "..."

                return summary

            except Exception as e:
                if attempt < self.max_retries - 1:
                    logging.warning(
                        f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œ{attempt+1}/{self.max_retries}æ¬¡é‡è¯•ä¸­..."
                    )
                    time.sleep(self.retry_delay * (attempt + 1))
                else:
                    logging.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                    return self._generate_fallback_summary(extracted_info)

    def _build_user_input(self, transcript_text, extracted_info):
        """æž„å»ºå‘é€ç»™æ¨¡åž‹çš„ç”¨æˆ·è¾“å…¥"""
        # æå–æ„å›¾å’Œé™ˆè¿°
        intents = extracted_info.get("intent", [])
        statements = extracted_info.get("statements", [])

        # æ ¼å¼åŒ–é™ˆè¿°
        formatted_statements = []
        for statement in statements:
            if isinstance(statement, dict) and "content" in statement:
                formatted_statements.append(statement["content"])

        # æž„å»ºæç¤º
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆæ‘˜è¦ï¼š
        åŽŸå§‹æ–‡æœ¬
    {transcript_text[:1000]}... (æ–‡æœ¬å·²æˆªæ–­)

    å·²æå–çš„ä¿¡æ¯
    æ„å›¾: {", ".join(intents) if intents else "æœªè¯†åˆ«"}

    å…³é”®é™ˆè¿°: {chr(10).join([f"- {s}" for s in formatted_statements])}

    è¯·ç”Ÿæˆä¸€ä¸ªåŸºäºŽä»¥ä¸Šä¿¡æ¯çš„Markdownæ ¼å¼æ‘˜è¦ã€‚ç¡®ä¿æ‘˜è¦ä¸­æ˜Žç¡®åŒ…å«å·²æå–çš„æ„å›¾å’Œå…³é”®é™ˆè¿°ã€‚ """
        return prompt

    def _call_openai_api(self, text):
        """è°ƒç”¨OpenAI APIç”Ÿæˆæ‘˜è¦"""
        response = self.client.chat.completions.create(
            model=self.config["report_model"]["remote_openai"]["model"],
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": text},
            ],
            temperature=0.3,
        )
        return response.choices[0].message.content.strip()

    def _call_ollama_api(self, text):
        """è°ƒç”¨æœ¬åœ°Ollama APIç”Ÿæˆæ‘˜è¦"""
        payload = {
            "model": self.config["report_model"]["local_ollama"]["model"],
            "messages": [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": text},
            ],
            "stream": False,
            "temperature": 0.3,
        }

        response = requests.post(
            self.config["report_model"]["local_ollama"]["base_url"],
            json=payload,
            timeout=120,
        )
        response.raise_for_status()

        data = json.loads(response.text)
        return data["message"]["content"]

    def _generate_fallback_summary(self, extracted_info):
        """å½“APIè°ƒç”¨å¤±è´¥æ—¶ç”Ÿæˆå¤‡ç”¨æ‘˜è¦"""
        intents = extracted_info.get("intent", [])
        statements = extracted_info.get("statements", [])

        intent_str = "ã€".join(intents) if intents else "æœªè¯†åˆ«"

        statement_bullets = []
        for statement in statements:
            if isinstance(statement, dict) and "content" in statement:
                statement_bullets.append(f"- {statement['content']}")

        statement_str = (
            "\n".join(statement_bullets) if statement_bullets else "- æ— æ˜Žç¡®é™ˆè¿°"
        )

        fallback_summary = f"""## å†…å®¹æ‘˜è¦
        ä¸»é¢˜
    è¯¥å†…å®¹çš„ä¸»é¢˜æ— æ³•è‡ªåŠ¨è¯†åˆ«ã€‚

    æ„å›¾
    {intent_str}

    æ ¸å¿ƒå†…å®¹
    {statement_str}

    æ€»ç»“
    ç”±äºŽæŠ€æœ¯åŽŸå› ï¼Œæ— æ³•ç”Ÿæˆå®Œæ•´æ‘˜è¦ï¼Œä¸Šè¿°å†…å®¹ä»…ä¾›å‚è€ƒã€‚ """
        return fallback_summary
