# conda 环境安装
conda create -n TinyAISearch python=3.10
conda activate TinyAISearch
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# GPU版本的faiss安装
conda install conda-forge::faiss-gpu

# 完成crawl4ai包的后续初始化步骤
crawl4ai-setup 
# 验证是否安装成功
crawl4ai-doctor

# 配置
在 `config/config.json` 文件中配置模型和搜索引擎相关参数。

# 运行

# 处理数据集,根据message 字段 搜索得到 message_evidence 并且写回
python search.py


# 简介
一、整体设计思路
1. 分层处理架构：
- 预处理层：通过RecursiveCharacterTextSplitter实现智能分块（支持中英双语分隔符）
- 召回层：并行向量检索（FAISS）和词频检索（BM25）
- 融合层：RRF算法融合多路召回结果
- 优化层：交叉编码器重排序

1. 混合检索优势：
- 兼顾语义相似度（向量空间）和关键词匹配（词频统计）
- 解决单一检索模式的局限性（如术语精确匹配/同义扩展问题）

1. 工程化设计：
- 本地/云端双模式支持（通过配置文件切换）
- 异步请求+重试机制（保障服务可用性）
- 多粒度日志监控（错误分级记录）
- 进度可视化（tqdm进度条+时间预估）

二、核心召回方法解析
1. 向量相似度召回（Similarity类）
▪ 实现原理：
   - 基于稠密向量编码（Sentence Embedding）
   - 使用FAISS构建向量索引
   - 最近邻搜索（L2距离计算）

▪ 技术特点：
   - 支持本地部署（HuggingFace模型）
   - 兼容云端API（OpenAI格式接口）
   - 多查询融合（RRF算法）

▪ 适用场景：
   - 语义相关性检索（同义替换/概念扩展）
   - 长尾查询处理（非精确关键词匹配）

1. BM25召回
▪ 算法原理：
   - 基于词频统计的稀疏检索
   - TF-IDF加权改进版
   - jieba中文分词支持

▪ 技术特点：
   - 精确匹配优势
   - 计算效率高
   - 可解释性强

▪ 适用场景：
   - 专业术语精确匹配
   - 短文本快速检索
   - 关键词明确场景

1. 混合召回策略
▪ RRF算法融合：
   - Reciprocal Rank Fusion
   - 公式：score = Σ(1/(m + rank))
   - 平衡不同检索结果排序（m=60为平滑因子）

▪ 优势：
   - 避免单一算法偏置
   - 提升结果多样性
   - 自适应结果融合

三、重排序优化
1. 交叉编码器重排序
▪ 实现原理：
   - 使用BERT-style模型计算query-doc相关性
   - 云端（API服务）vs 本地（HuggingFace模型）

▪ 技术优势：
   - 精细化的相关性判别
   - 解决召回阶段的"语义偏差"
   - 支持端到端相关性学习

1. 处理流程：
召回结果 → 相关性打分 → 倒排重排序 → Top-K筛选

四、设计创新点
1. 动态分块策略
- 自适应中英文分隔符
- 重叠窗口设计（32字符）
- 元数据保留机制（保留来源信息）

1. 多路召回融合
```mermaid
graph TD
    A[用户查询] --> B{并行召回}
    B --> C[向量召回]
    B --> D[BM25召回]
    C --> E[RRF融合]
    D --> E
    E --> F[重排序]
    F --> G[最终结果]
```

1. 异常处理机制
- 分级重试策略（2次重试）
- 网络异常捕获（RequestException）
- 错误隔离设计（单文档失败不影响整体）

五、性能优化策略
1. 索引优化：
- FAISS量化压缩（float32精度）
- 批量处理加速（GPU加速）

1. 内存管理：
- 分块处理（256字符/块）
- 流式传输（避免大数据量内存溢出）

1. 预计算机制：
- 文档嵌入预处理
- 索引持久化支持（未显式展示）

该设计充分考虑了检索系统的四大核心需求：召回率、准确率、响应时间和系统稳定性，通过混合架构实现了精度与效率的平衡，适用于需要处理复杂查询场景的智能检索系统。